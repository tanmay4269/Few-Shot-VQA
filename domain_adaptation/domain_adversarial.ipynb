{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T08:51:42.030483Z",
     "start_time": "2024-08-26T08:51:41.905212Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/workspace')\n",
    "\n",
    "from DATrainer import *\n",
    "\n",
    "cfg = {\n",
    "    ### META ###\n",
    "    'name': 'DANN',\n",
    "\n",
    "    ### DataLoader ###\n",
    "    'n_classes': 10,\n",
    "    'labels': [\n",
    "        'yes', 'no',\n",
    "        '0', '1', '2', '3',  \n",
    "        'red', 'yellow', 'blue', 'green', \n",
    "    ],\n",
    "    \n",
    "    'mask_patches': True,\n",
    "    \n",
    "    'v2_samples_per_answer': 300,\n",
    "    'abs_samples_per_answer': 300,\n",
    "\n",
    "    'v2_samples_per_answer_train': 200,\n",
    "    'v2_samples_per_answer_val': 50,\n",
    "\n",
    "    'abs_samples_per_answer_train': 200,\n",
    "    'abs_samples_per_answer_val': 50,\n",
    "\n",
    "    'source_domain': 'abs',\n",
    "    \n",
    "    ### VLModel ###\n",
    "    'image_encoder': 'facebook/dinov2-base',\n",
    "    'text_encoder': 'bert-base-uncased',\n",
    "    \n",
    "    ## Embedder\n",
    "    'num_attn_heads': 8,\n",
    "    'fusion_mode': 'cat',\n",
    "    'num_stacked_attn': 1, \n",
    "    \n",
    "    'criss_cross__drop_p': 0.5,\n",
    "    'post_concat__drop_p': 0.0, \n",
    "    'embed_attn__add_residual': False,\n",
    "    'embed_attn__drop_p': 0.0,\n",
    "\n",
    "    ## Label Classifier\n",
    "    'label_classifier__use_bn': False,\n",
    "    'label_classifier__drop_p': 0.0,\n",
    "    'label_classifier__repeat_layers': [0, 0],\n",
    "\n",
    "    ## Domain Classifier\n",
    "    'domain_classifier__use_bn': True,\n",
    "    'domain_classifier__drop_p': 0.5,\n",
    "    'domain_classifier__repeat_layers': [2, 2], \n",
    "\n",
    "    ### Objective ###\n",
    "    # loss fn\n",
    "    'domain_adaptation_method': 'domain_adversarial',  # 'naive', 'importance_sampling', 'domain_adversarial'\n",
    "\n",
    "    ### Trainer ###\n",
    "    'relaxation_period': 3,  # epochs to wait where accuracy is dropping \n",
    "                            # below moving average before ending the run\n",
    "                            # (-1 to disable it)\n",
    "    \n",
    "    'batch_size': 150,\n",
    "    'epochs': 30,\n",
    "    'base_lr': 5e-4,\n",
    "    'weight_decay': 5e-4,\n",
    "\n",
    "    ### Logging ###\n",
    "    'print_logs': True,\n",
    "    # 'print_logs': False,\n",
    "\n",
    "    'weights_save_root': './weights/raw'\n",
    "}\n",
    "\n",
    "if True:\n",
    "    # v2\n",
    "    cfg['source_domain'] = 'v2'\n",
    "    trainer = DATrainer(cfg, vqa_v2, vqa_abs)\n",
    "    v2_ckpt_path = cfg['weights_save_path']\n",
    "\n",
    "    trainer.train(show_plot=True)\n",
    "\n",
    "    # abs\n",
    "    cfg['source_domain'] = 'abs'\n",
    "    trainer = DATrainer(cfg, vqa_v2, vqa_abs)\n",
    "    abs_ckpt_path = cfg['weights_save_path']\n",
    "\n",
    "    trainer.train(show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2_ckpt_path = './weights/raw/name=DANN__n_classes=10__v2_samples_per_answer=300__abs_samples_per_answer=150__source_domain=v2__base_lr=0.001__domain_adaptation_method=domain_adversarial__.pth'\n",
    "\n",
    "# abs_ckpt_path = './weights/raw/name=DANN__n_classes=10__v2_samples_per_answer=300__abs_samples_per_answer=150__source_domain=abs__base_lr=0.001__domain_adaptation_method=domain_adversarial__.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg['v2_ckpt'] = v2_ckpt_path\n",
    "cfg['abs_ckpt'] = abs_ckpt_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(v2_train_data, v2_val_data), (abs_train_data, abs_val_data), labels = data_processing_v2(cfg, vqa_v2, vqa_abs)\n",
    "model = VLModel(cfg, return_embeddings=True).cuda()\n",
    "\n",
    "def eval_domain_adaptation(eval_dataset, model_ckpt, evaluate_train=False):\n",
    "    if eval_dataset == 'v2':\n",
    "        train_data, val_data = v2_train_data, v2_val_data\n",
    "    elif eval_dataset == 'abs':\n",
    "        train_data, val_data = abs_train_data, abs_val_data\n",
    "\n",
    "    train_dataset = VQADataset(cfg, train_data)\n",
    "    val_dataset = VQADataset(cfg, val_data)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=cfg['batch_size'], shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=cfg['batch_size'], shuffle=True)\n",
    "\n",
    "    if model_ckpt == 'v2':\n",
    "        ckpt = cfg['v2_ckpt']\n",
    "    elif model_ckpt == 'abs':\n",
    "        ckpt = cfg['abs_ckpt']\n",
    "\n",
    "    state_dict = torch.load(ckpt, weights_only=True)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    dataloader = val_dataloader if not evaluate_train else train_dataloader\n",
    "\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    embeddings = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i_tokens, q_tokens, label in dataloader:\n",
    "            i_tokens = {key: value.cuda() for key, value in i_tokens.items()}\n",
    "            q_tokens = {key: value.cuda() for key, value in q_tokens.items()}\n",
    "            label = label.cuda()\n",
    "            \n",
    "            logits, embedding = model(i_tokens, q_tokens)\n",
    "            embeddings = np.concatenate((embeddings, embedding), axis=0) if embeddings is not None else embedding\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, predicted_indices = torch.max(logits, dim=1)\n",
    "            label_indices = torch.argmax(label, dim=1)\n",
    "            is_correct = (predicted_indices == label_indices)\n",
    "\n",
    "            total += label.shape[0]\n",
    "            correct += is_correct.sum().item()\n",
    "\n",
    "    accuracy = (correct / total)\n",
    "\n",
    "    source = 'v2 ' if model_ckpt == 'v2' else 'abs'\n",
    "    target = 'v2 ' if eval_dataset == 'v2' else 'abs'\n",
    "    split = 'train set' if evaluate_train else 'val set  '\n",
    "    print(f'{source} -> {target} | {split} \\t accuracy = {accuracy*100:.2f}%')\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2 -> v2\n",
    "v2_val_embeddings = eval_domain_adaptation(model_ckpt='v2', eval_dataset='v2', evaluate_train=False)\n",
    "v2_train_embeddings = eval_domain_adaptation(model_ckpt='v2', eval_dataset='v2', evaluate_train=True)\n",
    "\n",
    "# abs -> abs\n",
    "abs_val_embeddings = eval_domain_adaptation(model_ckpt='abs', eval_dataset='abs', evaluate_train=False)\n",
    "abs_train_embeddings = eval_domain_adaptation(model_ckpt='abs', eval_dataset='abs', evaluate_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2 -> abs\n",
    "v2_abs_val_embeddings = eval_domain_adaptation(model_ckpt='v2', eval_dataset='abs', evaluate_train=False)\n",
    "v2_abs_train_embeddings = eval_domain_adaptation(model_ckpt='v2', eval_dataset='abs', evaluate_train=True)\n",
    "\n",
    "# abs -> v2\n",
    "abs_v2_val_embeddings = eval_domain_adaptation(model_ckpt='abs', eval_dataset='v2', evaluate_train=False)\n",
    "abs_v2_train_embeddings = eval_domain_adaptation(model_ckpt='abs', eval_dataset='v2', evaluate_train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def plot_tsne(embeddings, plot_labels, perplexities, title=''):\n",
    "    n_plots = len(perplexities)\n",
    "    fig, axes = plt.subplots(1, n_plots, figsize=(6 * n_plots, 6))\n",
    "    \n",
    "    for idx, perplexity in enumerate(perplexities):\n",
    "        tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "        tsne_embeddings = tsne.fit_transform(embeddings)\n",
    "        \n",
    "        colors = {'vv': 'blue', 'aa': 'red', 'va': 'orange', 'av': 'violet'}\n",
    "        ax = axes[idx]\n",
    "        for i, plot_label in enumerate(plot_labels):\n",
    "                \n",
    "            ax.scatter(tsne_embeddings[i, 0], tsne_embeddings[i, 1], color=colors[plot_label])\n",
    "            ax.text(tsne_embeddings[i, 0] + 0.1, tsne_embeddings[i, 1], '', fontsize=9)\n",
    "        \n",
    "        ax.set_title(f'Perplexity = {perplexity}')\n",
    "    \n",
    "    custom_legend = [mpatches.Patch(color=colors[label], label=label) for label in set(plot_labels)]\n",
    "    fig.legend(handles=custom_legend)\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_v2 = len(v2_val_embeddings)\n",
    "n_abs = len(abs_val_embeddings)\n",
    "\n",
    "# v2 -> v2\n",
    "plot_tsne(v2_val_embeddings, ['vv'] * n_v2, perplexities=[2,4,8,16,32], title='v2->v2 (val set)')\n",
    "plot_tsne(v2_train_embeddings, ['vv'] * n_v2, perplexities=[2,4,8,16,32], title='v2->v2 (train set)')\n",
    "\n",
    "# abs -> abs\n",
    "plot_tsne(abs_val_embeddings, ['aa'] * n_abs, perplexities=[2,4,8,16,32], title='abs->abs (val set)')\n",
    "plot_tsne(abs_train_embeddings, ['aa'] * n_abs, perplexities=[2,4,8,16,32], title='abs->abs (train set)')\n",
    "\n",
    "# combined plot\n",
    "val_embeddings = np.concatenate((v2_val_embeddings, abs_val_embeddings), axis=0)\n",
    "plot_tsne(val_embeddings, ['vv'] * n_v2 + ['aa'] * n_abs, perplexities=[2,4,8,16,32], title='Same Domain (val set)')\n",
    "\n",
    "train_embeddings = np.concatenate((v2_train_embeddings, abs_train_embeddings), axis=0)\n",
    "plot_tsne(train_embeddings, ['vv'] * n_v2 + ['aa'] * n_abs, perplexities=[2,4,8,16,32], title='Same Domain (train set)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2 -> abs\n",
    "plot_tsne(v2_abs_val_embeddings, ['va'] * n_abs, perplexities=[2,4,8,16,32], title='v2->abs (val set)')\n",
    "plot_tsne(v2_abs_train_embeddings, ['va'] * n_abs, perplexities=[2,4,8,16,32], title='v2->abs (train set)')\n",
    "\n",
    "# abs -> v2\n",
    "plot_tsne(abs_v2_val_embeddings, ['av'] * n_v2, perplexities=[2,4,8,16,32], title='abs->v2 (val set)')\n",
    "plot_tsne(abs_v2_train_embeddings, ['av'] * n_v2, perplexities=[2,4,8,16,32], title='abs->v2 (train set)')\n",
    "\n",
    "# combined plot\n",
    "val_embeddings = np.concatenate((v2_abs_val_embeddings, abs_v2_val_embeddings), axis=0)\n",
    "plot_tsne(val_embeddings, ['va'] * n_abs + ['av'] * n_v2, perplexities=[2,4,8,16,32], title='Cross Domain (val set)')\n",
    "\n",
    "train_embeddings = np.concatenate((v2_abs_train_embeddings, abs_v2_train_embeddings), axis=0)\n",
    "plot_tsne(train_embeddings, ['va'] * n_abs + ['av'] * n_v2, perplexities=[2,4,8,16,32], title='Cross Domain (train set)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
