{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T08:51:42.030483Z",
     "start_time": "2024-08-26T08:51:41.905212Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/workspace')\n",
    "from trainer import * \n",
    "\n",
    "\n",
    "label_type_50 = {\n",
    "    'colors':        ['beige', 'black', 'blue', 'brown', 'gray', 'green', 'orange', 'pink', 'red', 'red and white', 'tan', 'white', 'yellow'],\n",
    "    'objects':       ['bench', 'chair', 'couch', 'floor', 'table', 'tv', 'blanket', 'book', 'frisbee', 'skateboard', 'soccer'],\n",
    "    'living-things': ['baby', 'bird', 'boy', 'cat', 'dog', 'fish', 'flowers', 'girl', 'man', 'mouse', 'tree', 'woman'],\n",
    "    'actions':       ['eating', 'playing', 'sitting', 'sleeping', 'standing', 'walking'],\n",
    "    'locations':     ['park', 'sidewalk', 'living room', 'on table', 'sky'],\n",
    "    'foods':         ['apple', 'pizza', 'sandwich', 'wine', 'food'],\n",
    "    'numbers':       ['0', '1', '2', '3', '4', '5', '6'],\n",
    "    'responses':     ['no', 'no one', 'nothing', 'yes'],\n",
    "    'directions':    ['left', 'right'],\n",
    "}\n",
    "\n",
    "label_type_20 = {\n",
    "    'colors':        ['beige', 'black', 'blue', 'brown', 'gray', 'green', 'orange', 'pink', 'red', 'red and white', 'tan', 'white', 'yellow'],\n",
    "    'objects':       ['bench', 'chair', 'couch', 'floor', 'table', 'tv', 'blanket', 'book', 'frisbee', 'skateboard', 'soccer', 'bike', 'car', 'bottle', 'cup', 'plate'],\n",
    "    'living-things': ['baby', 'bird', 'boy', 'cat', 'dog', 'fish', 'flowers', 'girl', 'man', 'mouse', 'tree', 'woman', 'duck', 'eagle', 'mushrooms'],\n",
    "    'actions':       ['eating', 'playing', 'sitting', 'sleeping', 'standing', 'walking', 'running', 'jumping', 'drinking'],\n",
    "    'locations':     ['park', 'sidewalk', 'living room', 'on table', 'sky', 'on floor', 'on grass'],\n",
    "    'foods':         ['apple', 'pizza', 'sandwich', 'wine', 'food', 'cheese', 'hot dog', 'bread', 'steak'],\n",
    "    'numbers':       ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11'],\n",
    "    'responses':     ['no', 'no one', 'nothing', 'yes'],\n",
    "    'directions':    ['left', 'right'],\n",
    "    'times':         ['morning', 'afternoon', 'evening', 'night'],\n",
    "    'weather':       ['sunny', 'clouds', 'sunset', 'rainy'],\n",
    "    'patterns':      ['checkered', 'floral'],\n",
    "}\n",
    "\n",
    "\n",
    "samples_per_answer = 50\n",
    "label_type_to_labels = label_type_50\n",
    "n_labels = 0\n",
    "for k in label_type_to_labels:\n",
    "    n_labels += len(label_type_to_labels[k])\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    \"name\": \"DANN\",\n",
    "    \n",
    "    ### DataLoader ###\n",
    "    \"n_classes\": n_labels,\n",
    "    \"n_types\": len(label_type_to_labels),\n",
    "    \n",
    "    'label_type_to_labels': label_type_to_labels,\n",
    "    \n",
    "    \"v2_samples_per_answer\": samples_per_answer,\n",
    "    \"abs_samples_per_answer\": samples_per_answer,\n",
    "    \n",
    "    \"v2_samples_per_answer_train\": samples_per_answer // 2,\n",
    "    \"abs_samples_per_answer_train\": samples_per_answer // 2,\n",
    "    \n",
    "    \"v2_samples_per_answer_val\": samples_per_answer // 2,\n",
    "    \"abs_samples_per_answer_val\": samples_per_answer // 2,\n",
    "    \n",
    "    \"source_domain\": \"v2\",\n",
    "    \n",
    "    ## Allow Min Samples\n",
    "    \"min_samples_mode\": True,  # will use atleast samples_per_answer per label\n",
    "    \n",
    "    ## Augmentations ##\n",
    "    'mask_patches': True,\n",
    "    \n",
    "    ### VLModel ###\n",
    "    \"image_encoder\": \"facebook/dinov2-base\",\n",
    "    \"text_encoder\": \"bert-base-uncased\",\n",
    "    \n",
    "    ## Embedder\n",
    "    \"num_attn_heads\": 8,\n",
    "    \"fusion_mode\": \"cat\",\n",
    "    \"num_stacked_attn\": 1,\n",
    "    \"criss_cross__drop_p\": 0.0,\n",
    "    \"post_concat__drop_p\": 0.0,\n",
    "    \"embed_attn__add_residual\": False,\n",
    "    \"embed_attn__drop_p\": 0.5,\n",
    "    \n",
    "    ## Label Type\n",
    "    'use_label_type_classifier': True,\n",
    "    # 'use_label_type_classifier': False,\n",
    "    'append_label_type_logits': False,\n",
    "    'give_location_of_labels_in_label_type': True,\n",
    "    \n",
    "    ## Label Classifier\n",
    "    \"label_classifier__use_bn\": True,\n",
    "    \"label_classifier__drop_p\": 0.2,\n",
    "    \"label_classifier__repeat_layers\": [0, 0],\n",
    "    \n",
    "    ## Domain Classifier\n",
    "    \"domain_classifier__use_bn\": True,\n",
    "    \"domain_classifier__drop_p\": 0.5,\n",
    "    \"domain_classifier__repeat_layers\": [2, 2],\n",
    "    \n",
    "    ### Objective ###\n",
    "    \"domain_adaptation_method\": \"domain_adversarial\",  # 'naive', 'importance_sampling', 'domain_adversarial'\n",
    "    \"train_modes\": ['DANN', 'label_type', 'label'],  # ['DANN', 'label_type', 'label']\n",
    "    \n",
    "    ### Trainer ###\n",
    "    \"relaxation_period\": 2,\n",
    "    \"epochs\": 30,\n",
    "    \"batch_size\": 600,  # 900\n",
    "    \"base_lr\": 1e-4,\n",
    "    \"weight_decay\": 5e-4,\n",
    "    \n",
    "    ### Logging ###\n",
    "    # \"print_logs\": False,\n",
    "    \"print_logs\": True,\n",
    "    \"show_plot\": True,\n",
    "    \"weights_save_root\": \"./weights/raw\",\n",
    "}\n",
    "\n",
    "if True:\n",
    "    # v2\n",
    "    cfg[\"source_domain\"] = \"v2\"\n",
    "    trainer = DATrainer(cfg, vqa_v2, vqa_abs)\n",
    "    v2_ckpt_path = cfg[\"weights_save_path\"]\n",
    "\n",
    "    trainer.train(show_plot=True)\n",
    "\n",
    "    # abs\n",
    "    # cfg[\"source_domain\"] = \"abs\"\n",
    "    # trainer = DATrainer(cfg, vqa_v2, vqa_abs)\n",
    "    # abs_ckpt_path = cfg[\"weights_save_path\"]\n",
    "\n",
    "    # trainer.train(show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2_ckpt_path = './weights/raw/name=DANN__n_classes=10__v2_samples_per_answer=300__abs_samples_per_answer=150__source_domain=v2__base_lr=0.001__domain_adaptation_method=domain_adversarial__.pth'\n",
    "\n",
    "# abs_ckpt_path = './weights/raw/name=DANN__n_classes=10__v2_samples_per_answer=300__abs_samples_per_answer=150__source_domain=abs__base_lr=0.001__domain_adaptation_method=domain_adversarial__.pth'\n",
    "\n",
    "# v2_ckpt_path = 'weights/raw/pKqoGdSZ.pth'\n",
    "# abs_ckpt_path = 'weights/raw/pKqoGdSZ.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg['v2_ckpt'] = v2_ckpt_path\n",
    "# cfg['abs_ckpt'] = abs_ckpt_path\n",
    "cfg['abs_ckpt'] = v2_ckpt_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "(v2_train_data, v2_val_data), (abs_train_data, abs_val_data) = data_processing_v2(cfg, vqa_v2, vqa_abs)\n",
    "model = DANN_VLModel(cfg, return_embeddings=True).cuda()\n",
    "\n",
    "def eval_domain_adaptation(eval_dataset, model_ckpt, evaluate_train=False):\n",
    "    if eval_dataset == 'v2':\n",
    "        train_data, val_data = v2_train_data, v2_val_data\n",
    "    elif eval_dataset == 'abs':\n",
    "        train_data, val_data = abs_train_data, abs_val_data\n",
    "\n",
    "    train_dataset = VQADataset(cfg, train_data)\n",
    "    val_dataset = VQADataset(cfg, val_data)\n",
    "    \n",
    "    val_size = len(val_dataset)\n",
    "    train_indices = random.sample(range(len(train_dataset)), val_size)\n",
    "    train_dataset = Subset(train_dataset, train_indices)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=cfg['batch_size'], shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=cfg['batch_size'], shuffle=True)\n",
    "\n",
    "    if model_ckpt == 'v2':\n",
    "        ckpt = cfg['v2_ckpt']\n",
    "    elif model_ckpt == 'abs':\n",
    "        ckpt = cfg['abs_ckpt']\n",
    "\n",
    "    state_dict = torch.load(ckpt, weights_only=True)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    dataloader = val_dataloader if not evaluate_train else train_dataloader\n",
    "\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    embeddings = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i_tokens, q_tokens, label, label_type in dataloader:\n",
    "            i_tokens = {key: value.cuda() for key, value in i_tokens.items()}\n",
    "            q_tokens = {key: value.cuda() for key, value in q_tokens.items()}\n",
    "            label, label_type = label.cuda(), label_type.cuda()\n",
    "            \n",
    "            label_logits, domain_logits, label_type_logits, embedding = model(i_tokens, q_tokens)\n",
    "            embeddings = np.concatenate((embeddings, embedding), axis=0) if embeddings is not None else embedding\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, predicted_indices = torch.max(label_logits, dim=1)\n",
    "            label_indices = torch.argmax(label, dim=1)\n",
    "            is_correct = (predicted_indices == label_indices)\n",
    "\n",
    "            total += label.shape[0]\n",
    "            correct += is_correct.sum().item()\n",
    "\n",
    "    accuracy = (correct / total)\n",
    "\n",
    "    source = 'v2 ' if model_ckpt == 'v2' else 'abs'\n",
    "    target = 'v2 ' if eval_dataset == 'v2' else 'abs'\n",
    "    split = 'train set' if evaluate_train else 'val set  '\n",
    "    print(f'{source} -> {target} | {split} \\t accuracy = {accuracy*100:.2f}%')\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2 -> v2\n",
    "v2_val_embeddings = eval_domain_adaptation(model_ckpt='v2', eval_dataset='v2', evaluate_train=False)\n",
    "v2_train_embeddings = eval_domain_adaptation(model_ckpt='v2', eval_dataset='v2', evaluate_train=True)\n",
    "\n",
    "# abs -> abs\n",
    "abs_val_embeddings = eval_domain_adaptation(model_ckpt='abs', eval_dataset='abs', evaluate_train=False)\n",
    "abs_train_embeddings = eval_domain_adaptation(model_ckpt='abs', eval_dataset='abs', evaluate_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2 -> abs\n",
    "v2_abs_val_embeddings = eval_domain_adaptation(model_ckpt='v2', eval_dataset='abs', evaluate_train=False)\n",
    "v2_abs_train_embeddings = eval_domain_adaptation(model_ckpt='v2', eval_dataset='abs', evaluate_train=True)\n",
    "\n",
    "# abs -> v2\n",
    "abs_v2_val_embeddings = eval_domain_adaptation(model_ckpt='abs', eval_dataset='v2', evaluate_train=False)\n",
    "abs_v2_train_embeddings = eval_domain_adaptation(model_ckpt='abs', eval_dataset='v2', evaluate_train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def plot_tsne(embeddings, plot_labels, perplexities, title=''):\n",
    "    n_plots = len(perplexities)\n",
    "    fig, axes = plt.subplots(1, n_plots, figsize=(6 * n_plots, 6))\n",
    "    \n",
    "    for idx, perplexity in enumerate(perplexities):\n",
    "        tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "        tsne_embeddings = tsne.fit_transform(embeddings)\n",
    "        \n",
    "        colors = {'vv': 'blue', 'aa': 'red', 'va': 'orange', 'av': 'violet'}\n",
    "        ax = axes[idx]\n",
    "        for i, plot_label in enumerate(plot_labels):\n",
    "                \n",
    "            ax.scatter(tsne_embeddings[i, 0], tsne_embeddings[i, 1], color=colors[plot_label])\n",
    "            ax.text(tsne_embeddings[i, 0] + 0.1, tsne_embeddings[i, 1], '', fontsize=9)\n",
    "        \n",
    "        ax.set_title(f'Perplexity = {perplexity}')\n",
    "    \n",
    "    custom_legend = [mpatches.Patch(color=colors[label], label=label) for label in set(plot_labels)]\n",
    "    fig.legend(handles=custom_legend)\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_v2 = len(v2_val_embeddings)\n",
    "n_abs = len(abs_val_embeddings)\n",
    "\n",
    "# v2 -> v2\n",
    "plot_tsne(v2_val_embeddings, ['vv'] * n_v2, perplexities=[2,4,8,16,32], title='v2->v2 (val set)')\n",
    "plot_tsne(v2_train_embeddings, ['vv'] * n_v2, perplexities=[2,4,8,16,32], title='v2->v2 (train set)')\n",
    "\n",
    "# abs -> abs\n",
    "plot_tsne(abs_val_embeddings, ['aa'] * n_abs, perplexities=[2,4,8,16,32], title='abs->abs (val set)')\n",
    "plot_tsne(abs_train_embeddings, ['aa'] * n_abs, perplexities=[2,4,8,16,32], title='abs->abs (train set)')\n",
    "\n",
    "# combined plot\n",
    "val_embeddings = np.concatenate((v2_val_embeddings, abs_val_embeddings), axis=0)\n",
    "plot_tsne(val_embeddings, ['vv'] * n_v2 + ['aa'] * n_abs, perplexities=[2,4,8,16,32], title='Same Domain (val set)')\n",
    "\n",
    "train_embeddings = np.concatenate((v2_train_embeddings, abs_train_embeddings), axis=0)\n",
    "plot_tsne(train_embeddings, ['vv'] * n_v2 + ['aa'] * n_abs, perplexities=[2,4,8,16,32], title='Same Domain (train set)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2 -> abs\n",
    "plot_tsne(v2_abs_val_embeddings, ['va'] * n_abs, perplexities=[2,4,8,16,32], title='v2->abs (val set)')\n",
    "plot_tsne(v2_abs_train_embeddings, ['va'] * n_abs, perplexities=[2,4,8,16,32], title='v2->abs (train set)')\n",
    "\n",
    "# abs -> v2\n",
    "plot_tsne(abs_v2_val_embeddings, ['av'] * n_v2, perplexities=[2,4,8,16,32], title='abs->v2 (val set)')\n",
    "plot_tsne(abs_v2_train_embeddings, ['av'] * n_v2, perplexities=[2,4,8,16,32], title='abs->v2 (train set)')\n",
    "\n",
    "# combined plot\n",
    "val_embeddings = np.concatenate((v2_abs_val_embeddings, abs_v2_val_embeddings), axis=0)\n",
    "plot_tsne(val_embeddings, ['va'] * n_abs + ['av'] * n_v2, perplexities=[2,4,8,16,32], title='Cross Domain (val set)')\n",
    "\n",
    "train_embeddings = np.concatenate((v2_abs_train_embeddings, abs_v2_train_embeddings), axis=0)\n",
    "plot_tsne(train_embeddings, ['va'] * n_abs + ['av'] * n_v2, perplexities=[2,4,8,16,32], title='Cross Domain (train set)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
